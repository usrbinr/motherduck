## code to prepare `config_csv` dataset goes here


config_csv <- tibble::tribble(
    ~name, ~description, ~type, ~default,
    "all_varchar", "Skip type detection and assume all columns are of type VARCHAR. This option is only supported by the read_csv function.", "BOOL", "false",
    "allow_quoted_nulls", "Allow the conversion of quoted values to NULL values", "BOOL", "true",
    "auto_detect", "Auto detect CSV parameters.", "BOOL", "true",
    "auto_type_candidates", "Types that the sniffer uses when detecting column types. The VARCHAR type is always included as a fallback option. See example.", "TYPE[]", "default types",
    "buffer_size", "Size of the buffers used to read files, in bytes. Must be large enough to hold four lines and can significantly impact performance.", "BIGINT", "16 * max_line_size",
    "columns", "Column names and types, as a struct (e.g., {'col1': 'INTEGER', 'col2': 'VARCHAR'}). Using this option disables auto detection of the schema.", "STRUCT", "(empty)",
    "comment", "Character used to initiate comments. Lines starting with a comment character (optionally preceded by space characters) are completely ignored; other lines containing a comment character are parsed only up to that point.", "VARCHAR", "(empty)",
    "compression", "Method used to compress CSV files. By default this is detected automatically from the file extension (e.g., t.csv.gz will use gzip, t.csv will use none). Options are none, gzip, zstd.", "VARCHAR", "auto",
    "dateformat", "Date format used when parsing and writing dates.", "VARCHAR", "(empty)",
    "date_format", "Alias for dateformat; only available in the COPY statement.", "VARCHAR", "(empty)",
    "decimal_separator", "Decimal separator for numbers.", "VARCHAR", ".",
    "delim", "Delimiter character used to separate columns within each line, e.g., , ; \\t. The delimiter character can be up to 4 bytes, e.g., ðŸ¦†. Alias for sep.", "VARCHAR", ",",
    "delimiter", "Alias for delim; only available in the COPY statement.", "VARCHAR", ",",
    "escape", "String used to escape the quote character within quoted values.", "VARCHAR", "\"",
    "encoding", "Encoding used by the CSV file. Options are utf-8, utf-16, latin-1. Not available in the COPY statement (which always uses utf-8).", "VARCHAR", "utf-8",
    "filename", "Add path of the containing file to each row, as a string column named filename. Relative or absolute paths are returned depending on the path or glob pattern provided to read_csv, not just filenames. Since DuckDB v1.3.0, the filename column is added automatically as a virtual column and this option is only kept for compatibility reasons.", "BOOL", "false",
    "force_not_null", "Do not match values in the specified columns against the NULL string. In the default case where the NULL string is empty, this means that empty values are read as zero-length strings instead of NULLs.", "VARCHAR[]", "[]",
    "header", "First line of each file contains the column names.", "BOOL", "false",
    "hive_partitioning", "Interpret the path as a Hive partitioned path.", "BOOL", "(auto-detected)",
    "ignore_errors", "Ignore any parsing errors encountered.", "BOOL", "false",
    "max_line_size or maximum_line_size", "Maximum line size, in bytes. Not available in the COPY statement.", "BIGINT", "2000000",
    "names or column_names", "Column names, as a list. See example.", "VARCHAR[]", "(empty)",
    "new_line", "New line character(s). Options are '\\r','\\n', or '\\r\\n'. The CSV parser only distinguishes between single-character and double-character line delimiters. Therefore, it does not differentiate between '\\r' and '\\n'.", "VARCHAR", "(empty)",
    "normalize_names", "Normalize column names. This removes any non-alphanumeric characters from them. Column names that are reserved SQL keywords are prefixed with an underscore character (_).", "BOOL", "false",
    "null_padding", "Pad the remaining columns on the right with NULL values when a line lacks columns.", "BOOL", "false",
    "nullstr or null", "Strings that represent a NULL value.", "VARCHAR or VARCHAR[]", "(empty)",
    "parallel", "Use the parallel CSV reader.", "BOOL", "true",
    "quote", "String used to quote values.", "VARCHAR", "\"",
    "rejects_scan", "Name of the temporary table where information on faulty scans is stored.", "VARCHAR", "reject_scans",
    "rejects_table", "Name of the temporary table where information on faulty lines is stored.", "VARCHAR", "reject_errors",
    "rejects_limit", "Upper limit on the number of faulty lines per file that are recorded in the rejects table. Setting this to 0 means that no limit is applied.", "BIGINT", "0",
    "sample_size", "Number of sample lines for auto detection of parameters.", "BIGINT", "20480",
    "sep", "Delimiter character used to separate columns within each line, e.g., , ; \\t. The delimiter character can be up to 4 bytes, e.g., ðŸ¦†. Alias for delim.", "VARCHAR", ",",
    "skip", "Number of lines to skip at the start of each file.", "BIGINT", "0",
    "store_rejects", "Skip any lines with errors and store them in the rejects table.", "BOOL", "false",
    "strict_mode", "Enforces the strictness level of the CSV Reader. When set to true, the parser will throw an error upon encountering any issues. When set to false, the parser will attempt to read structurally incorrect files. It is important to note that reading structurally incorrect files can cause ambiguity; therefore, this option should be used with caution.", "BOOL", "true",
    "thousands", "Character used to identify thousands separators in numeric values. It must be a single character and different from the decimal_separator option.", "VARCHAR", "(empty)",
    "timestampformat", "Timestamp format used when parsing and writing timestamps.", "VARCHAR", "(empty)",
    "timestamp_format", "Alias for timestampformat; only available in the COPY statement.", "VARCHAR", "(empty)",
    "types or dtypes or column_types", "Column types, as either a list (by position) or a struct (by name). See example.", "VARCHAR[] or STRUCT", "(empty)",
    "union_by_name", "Align columns from different files by column name instead of position. Using this option increases memory consumption.", "BOOL", "false"
)

usethis::use_data(config_csv, overwrite = TRUE)
