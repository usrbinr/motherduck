## code to prepare `config_parquet` dataset goes here


config_parquet <- tibble::tribble(
    ~Name, ~Description, ~Type, ~Default,
    "binary_as_string", "Parquet files generated by legacy writers do not correctly set the UTF8 flag for strings, causing string columns to be loaded as BLOB instead. Set this to true to load binary columns as strings.", "BOOL", "false",
    "encryption_config", "Configuration for Parquet encryption.", "STRUCT", "-",
    "filename", "Whether or not an extra filename column should be included in the result. Since DuckDB v1.3.0, the filename column is added automatically as a virtual column and this option is only kept for compatibility reasons.", "BOOL", "false",
    "file_row_number", "Whether or not to include the file_row_number column.", "BOOL", "false",
    "hive_partitioning", "Whether or not to interpret the path as a Hive partitioned path.", "BOOL", "(auto-detected)",
    "union_by_name", "Whether the columns of multiple schemas should be unified by name, rather than by position.", "BOOL", "false"
)



usethis::use_data(config_parquet, overwrite = TRUE)
